{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22c899df-d2b8-47e0-a780-5f474279c957",
   "metadata": {},
   "source": [
    "# Opdracht 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a3a314-d33b-4711-abfc-9910d9531c55",
   "metadata": {},
   "source": [
    "1. Let's get the CSV-file in jupyter\n",
    "    1. Let's clean the data\n",
    "        1. Correct the datatypes\n",
    "        2. Work on the duplicates\n",
    "        3. Work on outliers\n",
    "        4. Work on missing values\n",
    "            1. Does all the data make sense (verifying data with statistics)\n",
    "    2. Doing analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c478e777-339e-4ad1-a8c3-28c8d51f74b3",
   "metadata": {},
   "source": [
    "# 1. Lets get the first CSV-file in jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c12cbb-afa5-4e64-a36b-fe0f0e0eebc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "#import ipynb.fs.defs.functions2 as enzo\n",
    "\n",
    "# Remove restrictions on amount of rows and columns that can be displayed in pandas dataframes.\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "data = pd.read_csv(\"data/US_Accidents_June20.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1fb941-4cc9-41eb-8ced-5b6a9866b76d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## A. Let's clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a4748f-239d-41a7-9389-11a6722572c8",
   "metadata": {},
   "source": [
    "## a. Correct the datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6204c0e3-d768-418c-a365-4c2cf644bd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store datetime columns in datetime format\n",
    "data['parsed_starttime'] = pd.to_datetime(data['Start_Time'], format='%Y-%m-%d %H:%M:%S')\n",
    "data['parsed_endtime'] = pd.to_datetime(data['End_Time'], format='%Y-%m-%d %H:%M:%S')\n",
    "data['distance_km'] = data['Distance(mi)'] * 1.60934\n",
    "\n",
    "#State (part II)\n",
    "data['State'] = data['State'].astype('category') #transform the column State into the datatype category\n",
    "\n",
    "#Zipcode\n",
    "data['Zipcode'] = data['Zipcode'].astype('category') #transform the column zipcode into the datatype category\n",
    "\n",
    "#Country\n",
    "data.pop('Country') #we can exclude this variable as it all contains US as the whole dataset contains info from the US\n",
    "\n",
    "#Timezone\n",
    "data['Timezone'] = data['Timezone'].astype('category') #transform the column timezone into the datatype category\n",
    "\n",
    "#Airport_Code\n",
    "data['Airport_Code'] = data['Airport_Code'].astype('category') #transform the column Airport_code into the datatype category\n",
    "\n",
    "#Weather_Timestamp\n",
    "data['Weather_Timestamp'] = pd.to_datetime(data['Weather_Timestamp'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "#Temperature \n",
    "data['Temperature(C)'] = ((data['Temperature(F)'] - 32) * (5/9)) #this is the calculation that transforms the fahrenheit to celsius.\n",
    "\n",
    "#Wind_Chill(F) \n",
    "data['Wind_Chill(C)'] = ((data['Wind_Chill(F)'] - 32) * (5/9)) #this is the calculation that transforms the fahrenheit to celsius.\n",
    "\n",
    "#Pressure(in) - \n",
    "data['Pressure(in)'] = data['Pressure(in)'].astype('float') #lets first convert the pressure to float in order to do calculations\n",
    "data['Pressure(hPa)'] = (data['Pressure(in)'] * 33.86389) #this is the calculation that transforms it from inHg to hPa\n",
    "\n",
    "#Visibility(mi)\n",
    "data['Visibility(mi)'] = data['Visibility(mi)'].astype('float') #lets first convert the pressure to float in order to do calculations\n",
    "data['Visibility(m)'] = (data['Visibility(mi)'] * 1609.344) #this is the calculation that transforms the fahrenheit to celsius.\n",
    "\n",
    "#Wind_Direction\n",
    "data['Wind_Direction'].fillna('nan', inplace=True) #transform the NaN to 'NaN'(string) as it is giving problems in further fixing Wind_Direction \n",
    "data['Wind_Direction'] = data['Wind_Direction'].str.lower() #in case of differnences lower/higher cases between categories, we can make every category description in lowercase letters\n",
    "mapping = {'east':'e', 'north':'n', 'south':'s', 'west':'w', 'variable':'other', 'var':'other'} #let's recategorize the potential categories\n",
    "data['Wind_Direction'] = data['Wind_Direction'].replace(mapping)  #this allows us to replace the transformations stored in the variable mapping\n",
    "data['Wind_Direction'] = data['Wind_Direction'].replace('nan', np.NaN, regex=True) #lets transform 'NaN' (string) back to NaN and give the outcome 'var' also the NaN-value\n",
    "\n",
    "#Wind_Speed(mph) \n",
    "data['Wind_Speed(kph)'] = (data['Wind_Speed(mph)'] * 1.60934) #this does to trick in transforming the data from mph to kph\n",
    "\n",
    "#Precipitation(in) \n",
    "data['Precipitation(cm)'] = (data['Precipitation(in)'] * 2.54) #this does the trick from inches to cm\n",
    "\n",
    "#Weather_Condition \n",
    "data['Weather_Condition'] = data['Weather_Condition'].astype('category') #transform the column Airport_code into the datatype category\n",
    "\n",
    "#lets loose the variables that we transformed, which are Temperature(F), Wind_Chill(F), Pressure(in), Visibility(mi), Wind_Speed(mph), Precipitation(in)\n",
    "data = data.drop(['Temperature(F)', 'Wind_Chill(F)','Pressure(in)', 'Visibility(mi)','Wind_Speed(mph)', 'Precipitation(in)'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e80f193-0ef9-4d8e-a5dc-0fd2c87f0e55",
   "metadata": {},
   "source": [
    "## b. Work on the duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167780a8-6f20-411f-b139-c66100f1d3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates() #lets drop full duplicates\n",
    "data.info() #we went from ... to ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79691530-b5a5-441b-ab19-6aad76f6e426",
   "metadata": {},
   "source": [
    "## c. Work on outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e9c20a-50cd-458f-af42-480aeaafa8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build boxplot - temperature \n",
    "sns.boxplot(x=data['Temperature(C)'])  #highest recorded temperature in US is 56.7 celsius, the lowest recorderd temperature âˆ’56.7. Those are then the limits which will be maintained\n",
    "data.loc[data['Temperature(C)'] > 56.7] = np.nan #replace values where it is higher than 56.7 with NAN's \n",
    "data.loc[data['Temperature(C)'] < -56.7] = np.nan #replace values where it is lower than -56.7 with NAN's \n",
    "\n",
    "#Build boxplot - Pressure(hPa) (Part I) - in hold\n",
    "sns.boxplot(x=data['Pressure(hPa)']) #it seems we have one observation around 2000 and 0 which seems very high and low compared ot the rest of the values so let's chech them out first - air pressure can be affected by altitude, temperature and humidity\n",
    "\n",
    "#Build boxplot - Wind_Speed(kph)\n",
    "sns.boxplot(x=data['Wind_Speed(kph)'])\n",
    "data.loc[data['Wind_Speed(kph)'] > 372] = np.nan #highest windspeed ever recorded in USA is 371.76 kph so everything above is, is not possible\n",
    "\n",
    "#Build boxplot - Precipitation(cm)\n",
    "sns.boxplot(x=data['Precipitation(cm)']) \n",
    "data.loc[data['Wind_Speed(kph)'] > 50] = np.nan #we don't find the values above 60 cm feasable as the highest amount of daily precipitation is for tennesse 21.082 cm (https://www.afsrepair.com/resources/rainiest-cities-towns-in-tennessee/) and for california is that 0.3302 cm in long beach which is around 15 km from the site (https://www.dailybreeze.com/2021/10/26/new-rainfall-records-set-at-lax-and-long-beach-airport/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f95838-9699-4ce7-9c10-2d39c61ad356",
   "metadata": {},
   "source": [
    "## d. Work on missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cff960f-169c-4330-81e0-35fa4abb7661",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets check the relative share of NA's within each column\n",
    "((data.isnull() | data.isna()).sum() * 100 / data.index.size).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4844e549-be6f-4236-a5d1-16027ec7fe93",
   "metadata": {},
   "source": [
    "### i. Does all the data make sense (verifying data with statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd16b96-11e1-4c81-8e3b-4fe9cdca52c5",
   "metadata": {},
   "source": [
    "# B. Doing analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9544db85-36e1-43fa-bc9e-ca6bec37c0a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
