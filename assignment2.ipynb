{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opdracht 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Let's get the CSV-file in jupyter\n",
    "    1. Let's clean the data\n",
    "        1. Correct the datatypes\n",
    "        2. Work on the duplicates\n",
    "        3. Work on outliers\n",
    "        4. Work on missing values\n",
    "            1. Does all the data make sense (verifying data with statistics)\n",
    "    2. Doing analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Lets get the first CSV-file in jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "#import ipynb.fs.defs.functions2 as enzo\n",
    "\n",
    "# Remove restrictions on amount of rows and columns that can be displayed in pandas dataframes.\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "data = pd.read_csv(\"data/US_Accidents_June20.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## A. Let's clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Correct the datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store datetime columns in datetime format\n",
    "data['parsed_starttime'] = pd.to_datetime(data['Start_Time'], format='%Y-%m-%d %H:%M:%S')\n",
    "data['parsed_endtime'] = pd.to_datetime(data['End_Time'], format='%Y-%m-%d %H:%M:%S')\n",
    "data['distance_km'] = data['Distance(mi)'] * 1.60934\n",
    "\n",
    "#State (part II)\n",
    "data['State'] = data['State'].astype('category') #transform the column State into the datatype category\n",
    "\n",
    "#Zipcode\n",
    "data['Zipcode'] = data['Zipcode'].astype('category') #transform the column zipcode into the datatype category\n",
    "\n",
    "#Country\n",
    "data.pop('Country') #we can exclude this variable as it all contains US as the whole dataset contains info from the US\n",
    "\n",
    "#Turning_Loop\n",
    "data.pop('Turning_Loop') #we can exclude this variable as it all contains False\n",
    "\n",
    "#Timezone\n",
    "data['Timezone'] = data['Timezone'].astype('category') #transform the column timezone into the datatype category\n",
    "\n",
    "#Airport_Code\n",
    "data['Airport_Code'] = data['Airport_Code'].astype('category') #transform the column Airport_code into the datatype category\n",
    "\n",
    "#Weather_Timestamp\n",
    "data['Weather_Timestamp'] = pd.to_datetime(data['Weather_Timestamp'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "#Temperature \n",
    "data['Temperature(C)'] = ((data['Temperature(F)'] - 32) * (5/9)) #this is the calculation that transforms the fahrenheit to celsius.\n",
    "\n",
    "#Wind_Chill(F) \n",
    "data['Wind_Chill(C)'] = ((data['Wind_Chill(F)'] - 32) * (5/9)) #this is the calculation that transforms the fahrenheit to celsius.\n",
    "\n",
    "#Pressure(in) - \n",
    "data['Pressure(in)'] = data['Pressure(in)'].astype('float') #lets first convert the pressure to float in order to do calculations\n",
    "data['Pressure(hPa)'] = (data['Pressure(in)'] * 33.86389) #this is the calculation that transforms it from inHg to hPa\n",
    "\n",
    "#Visibility(mi)\n",
    "data['Visibility(mi)'] = data['Visibility(mi)'].astype('float') #lets first convert the pressure to float in order to do calculations\n",
    "data['Visibility(km)'] = (data['Visibility(mi)'] * 1609.344) #this is the calculation that transforms the mi to km.\n",
    "\n",
    "#Wind_Direction\n",
    "data['Wind_Direction'].fillna('nan', inplace=True) #transform the NaN to 'NaN'(string) as it is giving problems in further fixing Wind_Direction \n",
    "data['Wind_Direction'] = data['Wind_Direction'].str.lower() #in case of differnences lower/higher cases between categories, we can make every category description in lowercase letters\n",
    "mapping = {'east':'e', 'north':'n', 'south':'s', 'west':'w', 'variable':'other', 'var':'other'} #let's recategorize the potential categories\n",
    "data['Wind_Direction'] = data['Wind_Direction'].replace(mapping)  #this allows us to replace the transformations stored in the variable mapping\n",
    "data['Wind_Direction'] = data['Wind_Direction'].replace('nan', np.NaN, regex=True) #lets transform 'NaN' (string) back to NaN and give the outcome 'var' also the NaN-value\n",
    "\n",
    "#Wind_Speed(mph) \n",
    "data['Wind_Speed(kph)'] = (data['Wind_Speed(mph)'] * 1.60934) #this does to trick in transforming the data from mph to kph\n",
    "\n",
    "#Precipitation(in) \n",
    "data['Precipitation(cm)'] = (data['Precipitation(in)'] * 2.54) #this does the trick from inches to cm\n",
    "\n",
    "#Weather_Condition \n",
    "data['Weather_Condition'] = data['Weather_Condition'].astype('category') #transform the column Airport_code into the datatype category\n",
    "\n",
    "#lets loose the variables that we transformed, which are Temperature(F), Wind_Chill(F), Pressure(in), Visibility(mi), Wind_Speed(mph), Precipitation(in)\n",
    "data = data.drop(['Temperature(F)', 'Wind_Chill(F)','Pressure(in)', 'Visibility(mi)','Wind_Speed(mph)', 'Precipitation(in)'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Work on the duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate rows\n",
    "data.drop_duplicates(inplace = True)\n",
    "#data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. Work on outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build boxplot - temperature \n",
    "sns.boxplot(x=data['Temperature(C)'])  #highest recorded temperature in US is 56.7 celsius, the lowest recorderd temperature âˆ’56.7. Those are then the limits which will be maintained\n",
    "data.loc[data['Temperature(C)'] > 56.7] = np.nan #replace values where it is higher than 56.7 with NAN's \n",
    "data.loc[data['Temperature(C)'] < -56.7] = np.nan #replace values where it is lower than -56.7 with NAN's \n",
    "\n",
    "#Build boxplot - Pressure(hPa) (Part I) - in hold\n",
    "sns.boxplot(x=data['Pressure(hPa)']) #it seems we have one observation around 2000 and 0 which seems very high and low compared ot the rest of the values so let's chech them out first - air pressure can be affected by altitude, temperature and humidity\n",
    "\n",
    "#Build boxplot - Wind_Speed(kph)\n",
    "sns.boxplot(x=data['Wind_Speed(kph)'])\n",
    "data.loc[data['Wind_Speed(kph)'] > 372] = np.nan #highest windspeed ever recorded in USA is 371.76 kph so everything above is, is not possible\n",
    "\n",
    "#Build boxplot - Precipitation(cm)\n",
    "sns.boxplot(x=data['Precipitation(cm)']) \n",
    "data.loc[data['Wind_Speed(kph)'] > 50] = np.nan #we don't find the values above 50 cm feasable as the highest amount of daily precipitation is for tennesse 21.082 cm (https://www.afsrepair.com/resources/rainiest-cities-towns-in-tennessee/) and for california is that 0.3302 cm in long beach which is around 15 km from the site (https://www.dailybreeze.com/2021/10/26/new-rainfall-records-set-at-lax-and-long-beach-airport/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d. Work on missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets check the relative share of NA's within each column\n",
    "((data.isnull() | data.isna()).sum() * 100 / data.index.size).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. Does all the data make sense (verifying data with statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Doing analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"parsed_data.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot -temperature + visibility grouped by severity \n",
    "sns.relplot(\n",
    "    data=data,\n",
    "    x=\"Temperature(C)\", y=\"Visibility(km)\",\n",
    "    hue=\"Severity\", style= \"Severity\"\n",
    ")\n",
    "# When visibility is low, around 0C and -25C are clusters of very severe accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist -distance groupded by severity\n",
    "sns.histplot(\n",
    "    data=data,\n",
    "    x=\"Distance(mi)\",\n",
    "    hue=\"Severity\", multiple='stack'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the number of observations in each severe levels while grouped by Stop.\n",
    "sns.catplot(x=\"Severity\", hue=\"Stop\", kind=\"count\",\n",
    "            data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the number of observations in each severe levels while grouped by Traffic_Calming.\n",
    "sns.catplot(x=\"Severity\", hue=\"Traffic_Calming\", kind=\"count\",\n",
    "            data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the number of observations in each severe levels while grouped by Traffic_Signal.\n",
    "sns.catplot(x=\"Severity\", hue=\"Traffic_Signal\", kind=\"count\",\n",
    "            data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the number of observations in each severe levels while grouped by Bump.\n",
    "sns.catplot(x=\"Severity\", hue=\"Bump\", kind=\"count\",\n",
    "            data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the number of observations in each severe levels while grouped by Junction.\n",
    "sns.catplot(x=\"Severity\", hue=\"Junction\", kind=\"count\",\n",
    "            data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the number of observations in each severe levels while grouped by Give_Way.\n",
    "sns.catplot(x=\"Severity\", hue=\"Give_Way\", kind=\"count\",\n",
    "            data=data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
